{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Purpose](#purpose)\n",
    "2. [EDA](#eda)\n",
    "3. [Model-building](#model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='purpose'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "\n",
    "The purpose of this notebook is to serve as a template for quick EDA and Model-building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import logging\n",
    "import warnings\n",
    "import dill # to save an instance of your notebook including any built models\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) # to surpress floating point numbers being displayed \n",
    "# in scientific notation when unnecessary.\n",
    "\n",
    "%config Application.log_level = \"ERROR\"\n",
    "\n",
    "warnings.filterwarnings(action='once') # to stop warnings from showing repeatedly \n",
    "\n",
    "def snakify(column_name):\n",
    "    '''\n",
    "    Function to convert pandas column names into snake case.\n",
    "    '''\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', column_name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"data.csv\") # create a pandas DataFrame from your data\n",
    "data.columns = [snakify(col) for col in data.columns]\n",
    "key = '' # if you have keys like address_id, customer_id, you should change to object from int etc.\n",
    "data[key] = data[key].astype(\"object\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how pervasive nulls are in each of the variables...\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for col in data.columns:\n",
    "    if int(round(1 - (data[col].isnull().sum() / len(data)), 2) * 100) != 100:\n",
    "        print(col, 'has',\n",
    "              int(round(1 - (data[col].isnull().sum() / len(data)), 2) * 100),\n",
    "              'per cent coverage.')\n",
    "        counter+=1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "if counter == 0:\n",
    "    print('All features are at 100% coverage.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for zero-heavy variables...\n",
    "\n",
    "for col in data.columns:\n",
    "    if int(round(len(data[col][data[col] == 0]) / len(data) * 100, 2)) != 0:\n",
    "        print(round(len(data[col][data[col] == 0]) / len(data) * 100, 2),\n",
    "              'per cent of', col, 'are zeroes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ''\n",
    "\n",
    "not_used = []\n",
    "features = [col for col in data.columns if col not in [key, target] and col not in not_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = 0.05 # 5 percent of whole data\n",
    "\n",
    "for feat in features:\n",
    "    data[feat].sample(samp * len(data)).boxplot(figsize=(10, 6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histograms of each of the variables...\n",
    "\n",
    "data[features].sample(samp * len(data)).hist(figsize=(10, 8), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairplots of the data...\n",
    "\n",
    "lst = [f for f in features]\n",
    "if target not in lst:\n",
    "    lst.append(target)\n",
    "corr = data[lst].corr()\n",
    "print(corr[target][:-1].sort_values(ascending=False))\n",
    "\n",
    "sb.pairplot(data[lst].sample(samp * len(data)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a heatmap of variable correlations...\n",
    "\n",
    "cmap = sb.diverging_palette(250, 10, as_cmap=True)\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "sb.heatmap(corr,\n",
    "           cmap=cmap,\n",
    "           annot=True,\n",
    "           xticklabels=corr.columns,\n",
    "           yticklabels=corr.columns,\n",
    "           linewidths=.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple linear regression and feature scaling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler # use robust to better handle outliers\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# if you're building a basic neural network...\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def mean_bias_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(y_true - y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
